---
title: "General Analysis"
author: "Max Cummins"
date: "`r Sys.Date()`"
output:
  html_document: 
    theme: spacelab
    toc: true
    toc_float: true
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(#
#	eval = FALSE,
#	message = FALSE,
#	warning = FALSE,
#	include = FALSE
#)
#if (!require("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")

#BiocManager::install("ggtree")

#Read in our packages
library(tidyverse)
library(vroom)
library(ggplot2)
library(xml2)
library(ggrepel)
library(caret)
library(here)
library(ggtree)
library(eulerr)
library(igraph)
library(ggalluvial)
library(hues)
library(ggpubr)
library(paletteer)
library(ggVennDiagram)

#knitr::opts_chunk$set(echo = TRUE, root.dir = here::here())

#Define our not in function
`%nin%` <- Negate(`%in%`)
```

# Data import

First we read in our main dataset of genotypic data and our tree.

```{r Merge_analysis_outputs, warning=FALSE}

genometa <- vroom("../delims/genometa_n5471.txt", show_col_types = FALSE)

#Read in our tree
tree <- ggtree::read.tree("../analysis/RapidNJ_5471.nwk")

#Remove quotes from sample names
tree$tip.label <- gsub("'", '', tree$tip.label)
tree$tip.label <- gsub("\\.fa", "", tree$tip.label)

#Create a list of samples in our cohort
sample_names <- tree$tip.label %>% as.data.frame() %>% rename('name' = '.')

# Print a message detailing the count of samples
cat("The number of samples in the tree is", nrow(sample_names), "\n")
```

# Compute general collection stats

Next we generate some summary statistics on our collection

```{r warning=FALSE, message=FALSE}
# Generate a table of collection statistics relating to source niche
breakdown <- genometa %>% group_by(Revised_Source_Niche) %>% tally(sort = T)  %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~"Total")))

breakdown %>% mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>% rename('Count' = n) %>% knitr::kable(., align = 'c')
```

# Breakdown by year

```{r warning=FALSE, message=FALSE}
# Determine genomes sequenced before vs after 2001
genometa %>% group_by(Collection_Year >= 2001) %>% tally()  %>% knitr::kable(., align = 'c')
```

# Source breakdown

```{r warning=FALSE, message=FALSE}
#Generate a table showing whether human genomes were sourced from intestinal or extraintestinal sites 
sources <- genometa %>% filter(Revised_Source_Niche == "Human") %>% group_by(Intestinal_or_Extraintestinal) %>% tally(sort=T)   %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~"Total")))

sources %>% mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>% rename('Count' = n)  %>% knitr::kable(., align = 'c')

```

```{r warning=FALSE, message=FALSE}
#Generate a table showing whether livestock genomes were sourced from intestinal or extraintestinal sites
sources <- genometa %>% filter(Revised_Source_Niche == "Livestock") %>% group_by(Intestinal_or_Extraintestinal) %>% tally(sort=T)   %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~"Total")))

sources %>% mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>% rename('Count' = n)  %>% knitr::kable(., align = 'c')
```

# Define our source and phylogroup colours

```{r warning=FALSE, message=FALSE}
#Define source colours
source_cols <- c("Companion Animal" = "#59398d",
         "Environmental" = "#709b46",
         "Food" = "#c09f3d",
         "Human" = "#48c595",
         "Livestock" =  "#c26bbc",
         "Wild Animal" = "#b9553d")

#Define our colours for our phylogroups
clermont_cols <- c('#ffe119', '#4363d8', '#f58231', '#dcbeff', '#800000', '#000075', '#9A6324', 'red', '#3cb44b',  'white', '#a9a9a9', 'black')

#Assign our color names for phylogroups
names(clermont_cols) <- c("A", "B1",  "B2", "C", "D", "E", "F", "G", "E or cladeI", "cladeI", "cladeIII", "cladeIV")
```

# Figure 1

Here we produce part 1 of figure 1 - a bubble plot showing the distribution of isolates by source, year and state of collection.

```{r warning=FALSE, message=FALSE}
# Tally genomes by source, year and state of collection
data_summary <- genometa %>%
  group_by(Revised_Source_Niche, Collection_Year, State) %>%
  mutate(State = replace_na(State, "Unknown")) %>%
  summarise(Count = n(), .groups = 'drop')

# Create the bubble plot
figure_1 <- ggplot(data_summary, aes(x = Collection_Year, y = Revised_Source_Niche)) +
  geom_jitter(aes(size = Count, color = State), height = 0.2, alpha = 0.7) +
  scale_size(range = c(1, 10), name = "Number of isolates") +
  geom_hline(yintercept = seq_along(unique(data_summary$Revised_Source_Niche)) - 0.5, color = "grey80") + # Add separating lines
  scale_x_continuous(breaks = seq(1986, 2023, by = 1)) + # Show every year on the x-axis
  scale_color_manual(values = c("ACT" = "lightblue", "NSW" = "orange", "NT" = "darkred", "QLD" = "purple", 
                                "SA" = "red", "TAS" = "green", "WA" = "pink", "VIC" = "darkgreen", 
                                "Unknown" = "grey"), name = "State") +
  theme_minimal() +
  labs(x = "Year of collection", y = "Source") +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    axis.text.y = element_text(size = 10),
    legend.position = "right",
    panel.background = element_rect(fill = "white", color = NA),
    plot.background = element_rect(fill = "white", color = NA),
    plot.margin = unit(c(1.5, 0.5, 0.5, 0.5), "cm")  # Extra space for the title
  ) +
  scale_y_discrete(expand = c(0.025, 0.15))


ggsave(plot = figure_1, filename =  "../figures/Final_Figures/Figure_1A.pdf", width = 8, height = 6)

figure_1
```

# Figure 1B

Next we produce part b of figure 1 - an alluvial plot showing the distribution of isolates by source niche, source type and intestinal or extraintestinal origin.

```{r warning=FALSE, message=FALSE}
# Aggregate the data to count the number of isolates for each combination of Year and Source
agg_data <- genometa %>%
  group_by(Revised_Source_Niche, Revised_Source_Type, Intestinal_or_Extraintestinal) %>%
  mutate(Revised_Source_Type = fct_lump_min(Revised_Source_Type, 10)) %>%
  summarise(Isolates = n())

# Create the alluvial plot
figure_1b <- ggplot(agg_data,
       aes(axis1 = Revised_Source_Niche, axis2 = Revised_Source_Type, axis3 = Intestinal_or_Extraintestinal, y = Isolates)) +
  geom_alluvium(aes(fill = Revised_Source_Niche), width = 1/12) +
  geom_stratum(fill = "white", width = 1/12, color = "black") +
  #geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
  scale_x_discrete(limits = c("Source Niche", "Source Type", "Site of Origin"), expand = c(0.05, 0.05)) +
  scale_y_continuous(breaks = seq(0, 5471, by = 200), expand = c(0,0)) + # Show every year on the x-axis
  scale_fill_manual(values = source_cols) +
  theme(legend.position = "none",
        panel.background = element_rect(fill = "grey95", color = NA), # Ensure the panel background is white
    ) +
  labs(#title = "",
       x = "",
       y = "Number of Isolates")

#Save our plot
ggsave(plot = figure_1b, filename =  "../figures/Final_Figures/Figure_1B.pdf", width = 8, height = 6)

#Print our plot
figure_1b
```

To assist in producing the alluvial plot, we generate a color swatch for each of the source niches, source types and intestinal or extraintestinal origins for use in photo editor.

```{r warning=FALSE, message=FALSE}
# Generate the color palette
Niche_cols <- source_cols


# Create a data frame for the color swatch plot
color_swatch <- data.frame(
  Revised_Source_Niche = names(Niche_cols),
  Color = Niche_cols
)

# Create the swatch plot
cols_plot <- ggplot(color_swatch, aes(x = Revised_Source_Niche, y = 0.5, fill = Revised_Source_Niche)) +
  geom_tile(color = "black", width = 0.5, height = 0.5) +
  scale_fill_manual(values = Niche_cols) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    legend.position = "none"
  ) +
  labs(title = "Color Swatch for Source Niche")

#Show our plot
cols_plot
```

Another pallette for source type

```{r warning=FALSE, message=FALSE}
# Generate the color palette
Revised_Source_Type_cols <- iwanthue(length(unique(agg_data$Revised_Source_Type)))
names(Revised_Source_Type_cols) <- unique(agg_data$Revised_Source_Type)

# Create a data frame for the color swatch plot
color_swatch <- data.frame(
  Revised_Source_Type = names(Revised_Source_Type_cols),
  Color = Revised_Source_Type_cols
)

# Create the swatch plot
cols_plot <- ggplot(color_swatch, aes(x = Revised_Source_Type, y = 1, fill = Revised_Source_Type)) +
  geom_tile(color = "black", width = 0.9, height = 0.9) +
  scale_fill_manual(values = Revised_Source_Type_cols) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    legend.position = "none"
  ) +
  labs(title = "Color Swatch for Source Type")

#Show our plot
cols_plot
```

And one more for whether genomes are intestinal or extraintestinal:

```{r warning=FALSE, message=FALSE}
# Generate the color palette
Intestinal_or_Extraintestinal_type_cols <- iwanthue(length(unique(agg_data$Intestinal_or_Extraintestinal)))
names(Intestinal_or_Extraintestinal_type_cols) <- unique(agg_data$Intestinal_or_Extraintestinal)

# Create a data frame for the color swatch plot
color_swatch <- data.frame(
  Intestinal_or_Extraintestinal = names(Intestinal_or_Extraintestinal_type_cols),
  Color = Intestinal_or_Extraintestinal_type_cols
)

# Create the swatch plot
cols_plot <- ggplot(color_swatch, aes(x = Intestinal_or_Extraintestinal, y = 1, fill = Intestinal_or_Extraintestinal)) +
  geom_tile(color = "black", width = 0.9, height = 0.9) +
  scale_fill_manual(values = Intestinal_or_Extraintestinal_type_cols) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    legend.position = "none"
  ) +
  labs(title = "Color Swatch for Intestinal or Extraintestinal")

#Show our plot
cols_plot
```

Here we generate a table of collection statistics relating to phylogroup

```{r warning=FALSE, message=FALSE}
# Generate a table of collection statistics relating to phylogroup
# Consensus_phylogroup is the most common phylogroup for a given ST (some genomes phylogroup incorrectly when sample sizes are large)
phylogroups <- genometa %>% group_by(Consensus_phylogroup) %>% tally(sort=T)   %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~"Total")))

# Plot our table
phylogroups %>% mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>% rename('Count' = n)  %>% knitr::kable(., align = 'c')
```

```{r warning=FALSE, message=FALSE}
#Most B2 (n=_/2,240; _%) and D (n=_/803; _%) genomes were from humans. While _% (n=_/968) of phylogroup A and _% (n=_/711) of phylogroup B1 genomes were from humans, the majority were sourced from wild animals (A: n=_/968; B1: n=_/711), livestock (A: n=_/968; B1: n=_/711) and environmental (A: n=_/968; B1: n=_/711) sources (Figure 2).

phylogroups_by_Source <- genometa %>% group_by(Consensus_phylogroup, Revised_Source_Niche) %>% tally(sort=T)   %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~"Total")))

#Plot our table
phylogroups_by_Source %>% mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>% rename('Count' = n) %>% arrange(Consensus_phylogroup, desc(Count))  %>% knitr::kable(., align = 'c')
```

```{r warning=FALSE, message=FALSE}
#Tally our STs
STs <- genometa %>% group_by(ST_new) %>% tally(sort=T)

#Produce a table of STs and their counts
STs <- STs %>% mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>% rename('Count' = n) %>% ungroup() %>% mutate(Novel = if_else(str_detect(ST_new, "^[^0-9]"), "Yes", "No"))

#Plot our table of known vs non-typed ('Novel') STs
STs %>% group_by(Novel) %>% tally() %>% knitr::kable(., align = 'c')
```

```{r warning=FALSE, message=FALSE}
#Singletons
STs %>% group_by(Count == 1) %>% tally() %>% rename("STs which are singletons" = `Count == 1`) %>% knitr::kable(., align = 'c')
```

```{r warning=FALSE, message=FALSE}
#Top 30 ST Count
top_30_ST_count <- STs %>% head(30) %>% select(Count) %>% sum()

# Print a message detailing the count of samples in the top 30 STs
cat("The number of samples in the top 30 STs is", top_30_ST_count, "\n")

#Top 30 STs as percentage of dataset
top_30_ST_as_perc <- STs %>% head(30) %>% select(Count) %>% sum()/5471

# Print a message detailing the count of samples in the top 30 STs as a percentage of the dataset
cat("The top 30 STs as a percentage of the dataset is", scales::percent(top_30_ST_as_perc, accuracy = 0.01), "\n")
```

# Figure 2 - Part A

```{r Part A, echo=FALSE, warning=FALSE}
#Create the tree
tree_df <- genometa %>%
  select(name, Revised_Source_Niche, clermontyping..clermontyping_phylogroup, Revised_Source_Type, State, Intestinal_or_Extraintestinal) %>%
  mutate(State = replace_na(State, "Unknown")) %>%
  mutate(Revised_Source_Type = fct_lump_min(Revised_Source_Type, 10))
  

p2 <- ggtree(tree,
        layout = 'circular',
        open.angle = 0) %<+%
        tree_df +
  geom_tree(size = 0.2)

tree_df <- p2$data %>% filter(isTip == TRUE) %>% select(State, label, clermontyping..clermontyping_phylogroup, Revised_Source_Type, Revised_Source_Niche, Intestinal_or_Extraintestinal) %>% column_to_rownames('label')

p3 <- gheatmap(
        p = p2,
        data = tree_df,
        colnames_offset_y = -0.1,
        font.size = 1.5,
        hjust = 0,
        colnames = TRUE,
        offset = 1,
        width = 0.3,
        color = rgb(220, 220, 220, max = 255, alpha = 0)
        ) +
theme(legend.position = "right") +#,
        #legend.box = "vertical",
        #legend.key.size = unit(1, "mm"),
        #legend.title = element_blank(),
        #legend.text = element_text(size = 8)
        #) +
scale_fill_manual(
        values = c(source_cols, clermont_cols, Intestinal_or_Extraintestinal_type_cols, Revised_Source_Type_cols, c("ACT" = "lightblue", "NSW" = "orange", "NT" = "darkred", "QLD" = "purple", 
                                "SA" = "red", "TAS" = "green", "WA" = "pink", "VIC" = "darkgreen", 
                                "Unknown" = "grey")),
        na.value = 'grey'
        ) 

#Save our plot
ggsave(plot = p3, filename =  "../figures/Final_Figures/Figure_2A.pdf", width = 12, height = 8)

#Print our plot
p3
```

# Figure 2 - Part B

```{r warning=FALSE, message=FALSE}
# Prepare the data by counting occurrences
data_summary <- genometa %>%
  group_by(Revised_Source_Niche, Consensus_phylogroup) %>%
  mutate(Consensus_phylogroup = as.factor(rev(sort(Consensus_phylogroup)))) %>% 
  summarise(Count = n(), .groups = 'drop')

# Create the plot
fig2b <- ggplot(data_summary, aes(x = Revised_Source_Niche, y = Count, fill = Consensus_phylogroup)) +
  geom_bar(stat = "identity", position = "fill") +
  coord_flip() +  # Flips the axes to match the original plot's orientation
  scale_y_continuous(labels = scales::percent) +  # Converts y-axis into percentage
    theme(axis.text.y = element_text(size = 20),
        axis.text.x = element_text(size = 20),
        axis.title.y = element_text(size = 24),
        axis.title.x = element_text(size = 24),
        panel.background = element_rect(fill = "white", color = NA),
        legend.position = "none") +  # Optional: Clean minimalistic theme
  labs(x = "Source Niche", y = "Percentage", fill = "Phylogroup") +  # Labeling axes and legend
  scale_fill_manual(values = clermont_cols)

#Save our plot
ggsave(plot = fig2b, filename =  "../figures/Final_Figures/Figure_2B.pdf", width = 12, height = 12)

#Print our plot
fig2b
```

# Figure 2 - Part C

```{r warning=FALSE, message=FALSE}
# Prepare the data by counting occurrences
data_summary <- genometa %>%
  mutate(ST_other = fct_lump_n(paste0("ST",ST_new), 10)) %>%
  group_by(ST_other, Revised_Source_Niche) %>%
  summarise(Count = n(), .groups = 'drop')

# Create the plot
fig2c <- ggplot(data_summary, aes(x = ST_other, y = Count, fill = Revised_Source_Niche)) +
  geom_bar(stat = "identity", position = "fill") +
  coord_flip() +  # Flips the axes to match the original plot's orientation
  scale_y_continuous(labels = scales::percent) +  # Converts y-axis into percentage
    theme(axis.text.y = element_text(size = 20),
        axis.text.x = element_text(size = 20),
        axis.title.y = element_text(size = 24),
        axis.title.x = element_text(size = 24),
        panel.background = element_rect(fill = "white", color = NA),
        legend.position = "none") +  # Optional: Clean minimalistic theme
  labs(x = "Sequence Type", y = "Percentage", fill = "Phylogroup") +  # Labeling axes and legend
  scale_fill_manual(values = source_cols)

#Save our plot
ggsave(plot = fig2c, filename =  "../figures/Final_Figures/Figure_2C.pdf", width = 12, height = 12)

#Print our plot
fig2c
```

```{r warning=FALSE, message=FALSE}
#In total, _ isolates (comprising _ isolate pairs) were identified as putative clusters; the remaining _ isolates exceeded this distance from any other isolate in the collection.

# If "../analysis/cgMLST_dists_5471.txt.gz" is present and "../analysis/cgMLST_dists_5471.txt" isnt, unzip the file
if (file.exists("../analysis/cgMLST_dists_5471.txt.gz") & !file.exists("../analysis/cgMLST_dists_5471.txt")) {
  system("gunzip ../analysis/cgMLST_dists_5471.txt.gz")
}

# Read in our cgMLST distances
cgmlst_dists <- vroom("../analysis/cgMLST_dists_5471.txt", show_col_types = FALSE)

cgmlst_dists <- cgmlst_dists %>%
  pivot_longer(
    cols = 2:ncol(cgmlst_dists),  # Ensure this references the correct data frame
    names_to = "Sample 2",
    values_to = "value"
  ) %>% rename('Sample 1' = `5471`)

cgmlst_dists <- cgmlst_dists %>% filter(`Sample 1` != `Sample 2`)

cgmlst_dists <- cgmlst_dists %>% filter(`Sample 1` %in% tree$tip.label & `Sample 2` %in% tree$tip.label)

#Isolate pairs
cgmlst_dists %>% filter(value <= 40) %>% nrow()

#Isolate count
cgmlst_dists %>% filter(value <= 40) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>% nrow()
```

```{r warning=FALSE, message=FALSE}
#Isolates with STs 131, 963, 1193, 95, 69, 80, 117, 457, 648 and 57 comprised _% (n=_/5,471) of the overall collection (Figure 2 C). 
#Count
STs %>% filter(ST_new %in% c(131, 963, 1193, 95, 69, 80, 117, 457, 648, 57)) %>% pull(Count) %>% sum()

#Perc
STs %>% filter(ST_new %in% c(131, 963, 1193, 95, 69, 80, 117, 457, 648, 57)) %>% pull(Count) %>% sum()/5471
```

# Data setup for SNP distances

```{r warning=TRUE}
# Initialize an empty data frame to store all sequence types' data
df_all_ST <- data.frame()

# Loop through directories containing SNP distance data
for (i in list.dirs("../analysis/SKA")) {
    # Check if directory name indicates distance data
    if (str_detect(string = i, pattern = "_dists")) {
        # Extract sequence type (ST) from the directory name
        ST <- gsub("_dists", "", basename(i))
        
        # Read in SNP distances
        dists <- read_delim(paste0(i, "/", ST, "_dist_100_SNP.distances.tsv"), 
                            delim = "\t", escape_double = FALSE, 
                            trim_ws = TRUE, show_col_types = FALSE)
        
        # Read in SNP Clusters
        clusts <- read_delim(paste0(i, "/", ST, "_dist_100_SNP.clusters.tsv"), 
                             delim = "\t", escape_double = FALSE, 
                             trim_ws = TRUE, show_col_types = FALSE)
        
        # Combine metadata and clusters for visualization in Microreact
        data_microreact <- left_join(clusts, genometa, by = c("ID" = "name")) %>%
                           select(ID, starts_with("Revised_Source"), Collection_Year, Collection, fimtyper..Fimtype, ColV, Cluster__autocolour)
        
        # Rename and reverse columns for joining
        data_microreact1 <- data_microreact %>%
                            rename("Sample 1" = ID) %>%
                            rev()
        
        data_microreact2 <- data_microreact %>%
                            rename("Sample 2" = ID)
        
        # Join SNP distance data with metadata
        dists2 <- inner_join(data_microreact1, dists, by = "Sample 1")
        dists2 <- inner_join(dists2, data_microreact2, by = "Sample 2")
        
        # Convert factor columns to character for easier manipulation
        dists2 <- dists2 %>% mutate(across(where(is.factor), as.character))
        
        # Create combinations of metadata fields
        dists_w_metadata <- dists2 %>%
                            rowwise() %>%
                            mutate(col1 = pmin(Revised_Source_Niche.x, Revised_Source_Niche.y),
                                   col2 = pmax(Revised_Source_Niche.x, Revised_Source_Niche.y),
                                   source_combo = paste0(col1, "/", col2, collapse = "")) %>%
                            select(-col1, -col2)
        
        dists_w_metadata <- dists_w_metadata %>%
                            rowwise() %>%
                            mutate(col1 = pmin(Revised_Source_Type.x, Revised_Source_Type.y),
                                   col2 = pmax(Revised_Source_Type.x, Revised_Source_Type.y),
                                   source_type_combo = paste0(col1, "/", col2, collapse = "")) %>%
                            select(-col1, -col2)
        
        # Assign ST labels
        dists_w_metadata$ST.x <- ST
        dists_w_metadata$ST.y <- ST
        
        # Append to main data frame
        df_all_ST <- rbind(df_all_ST, dists_w_metadata)
        
        # Optional: write data to file for Microreact (uncomment if needed)
        # write_delim(x = data_microreact1, file = paste0(i, "/", ST, "_metadata_microreact.tsv"), delim = "\t")
    }
}

# Filter the data to include only samples that are present in the phylogenetic tree
df_all_ST <- df_all_ST %>%
              as.data.frame() %>%
              filter(`Sample 1` %in% tree$tip.label & `Sample 2` %in% tree$tip.label)

# Filter for entries where source niches differ
dists_w_metadata_x_source <- df_all_ST %>%
                             as.data.frame() %>%
                             filter(Revised_Source_Niche.x != Revised_Source_Niche.y)

# Read in cgMLST clusters
cgMLST_clusters <- read_delim(file = "../analysis/clusters.txt", show_col_types = FALSE)

# Read in cgMLST clusters (additional column)
cgMLST_clusters_less_40 <- read_delim(file = "../analysis/clusters_40cgmlst.txt", show_col_types = FALSE)

cgMLST_clusters <- left_join(cgMLST_clusters, cgMLST_clusters_less_40)

# Join cgMLST distance data
distsnew <- inner_join(df_all_ST, cgmlst_dists, by = c("Sample 1", "Sample 2"))

# Combine all source metadata with distances
dists_w_metadata_all_source <- distsnew %>% as.data.frame()

# Further filter for SNP distances
df_all_ST_filtered_SNPs_all <- dists_w_metadata_all_source %>% as.data.frame()

```

# SNP distances

```{r warning=FALSE, message=FALSE}
##Of the _ cross-source pairs under analysis, _ (_%) exhibited SNP distances ≤ 100 SNPs

#Compute pairs
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% nrow()

#Compute strains
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>% nrow()
```

```{r warning=FALSE, message=FALSE}
#Compute pairs ≤ 100 SNPs
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs <= 100) %>% tally()

#Compute percent pairs ≤ 100 SNPs
tmp <- df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs <= 100) %>% tally()  %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ TRUE | FALSE))) %>%
  mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>%
  rename('Count' = n)# %>% arrange(Consensus_phylogroup, desc(Count))

knitr::kable(tmp, align = 'c')

#Compute strain count
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
  filter(SNPs <= 100) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>% nrow()  %>% knitr::kable(., align = 'c')
```

```{r warning=FALSE, message=FALSE}
##The SNP distance thresholds were further classified as follows: > 75 and ≤ 100 (n = _/_; _%), > 50 and ≤ 75 (n = _/_; _%), or > 20 and ≤ 50 (n = _/_; _%).

#Compute pairs > 75 ≤ 100 SNPs
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs > 75 & SNPs <= 100) %>% tally()  %>% knitr::kable(., align = 'c')

#Compute percent pairs > 75 ≤ 100 SNPs
tmp <- df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs > 75 & SNPs <= 100) %>% tally() %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ TRUE | FALSE))) %>%
  mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>%
  rename('Count' = n)# %>% arrange(Consensus_phylogroup, desc(Count))

knitr::kable(tmp, align = 'c')

#Compute strain count
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
  filter(SNPs > 75 & SNPs <= 100) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>% nrow()
```

```{r warning=FALSE, message=FALSE}
#Compute pairs > 50 ≤ 75 SNPs
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs > 50 & SNPs <= 75) %>% tally()  %>% knitr::kable(., align = 'c')

#Compute percent pairs > 50 ≤ 75 SNPs
tmp <- df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs > 50 & SNPs <= 75) %>% tally() %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ TRUE | FALSE))) %>%
  mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>%
  rename('Count' = n)# %>% arrange(Consensus_phylogroup, desc(Count))

knitr::kable(tmp, align = 'c')


#Compute strain count
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
  filter(SNPs > 50 & SNPs <= 75) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>% nrow()
```

```{r warning=FALSE, message=FALSE}

#Compute pairs > 20 ≤ 50 SNPs
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs > 20 & SNPs <= 50) %>% tally()  %>% knitr::kable(., align = 'c')

#Compute percent pairs > 20 ≤ 50 SNPs
tmp <- df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs > 20 & SNPs <= 50) %>% tally() %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ TRUE | FALSE))) %>%
  mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>%
  rename('Count' = n)# %>% arrange(Consensus_phylogroup, desc(Count))

knitr::kable(tmp, align = 'c')


#Compute strain count
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
  filter(SNPs > 20 & SNPs <= 50) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>% nrow()
```

```{r warning=FALSE, message=FALSE}

#Compute pairs <- 20 SNPs
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs <= 20) %>% tally()  %>% knitr::kable(., align = 'c')

#Compute percent pairs > 20 ≤ 50 SNPs
tmp <- df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(SNPs <= 20) %>% tally() %>% 
  bind_rows(summarise(.,
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ TRUE | FALSE))) %>%
  mutate(Percentage = scales::percent(n/max(n), accuracy = 0.01)) %>%
  rename('Count' = n)# %>% arrange(Consensus_phylogroup, desc(Count))

knitr::kable(tmp, align = 'c')


#Compute strain count
df_all_ST_filtered_SNPs_all %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
  filter(SNPs <= 20) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>% nrow()
```

# Figure 3

Note that this figure was used as the template for the final figure, which was generated using an image editor.

```{r warning=FALSE, message=FALSE}
# Load necessary libraries
library(dplyr)
library(eulerr)

# Set seed for reproducibility
set.seed(5)

# Define a function to filter and process intersource data
process_intersource_data <- function(df, snp_threshold) {
  df %>%
    filter(SNPs <= snp_threshold) %>%                    # Filter SNPs based on threshold
    filter(`Sample 1` != `Sample 2`) %>%                 # Exclude rows where Sample 1 equals Sample 2
    filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%  # Filter different source niches
    mutate(col1 = pmin(`Sample 1`, `Sample 2`),          # Get the minimum of Sample 1 and Sample 2
           col2 = pmax(`Sample 1`, `Sample 2`)) %>%      # Get the maximum of Sample 1 and Sample 2
    ungroup() %>%                                        # Ungroup the dataframe
    mutate(name_combo = paste0(col1, "/", col2)) %>%     # Create combination name
    select(-col1, -col2)                                 # Drop col1 and col2
}

# Process intersource data for different SNP thresholds
intersource_less_20 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 20)
intersource_less_50 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 50)
intersource_less_75 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 75)
intersource_less_100 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 100)
intersource_less_200 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 200)
intersource_less_500 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 500)
intersource_less_1000 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 1000)
intersource_less_2500 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 2500)
intersource_less_5000 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 5000)
intersource_less_7500 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 7500)
intersource_less_10000 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 10000)
intersource_total_11350 <- process_intersource_data(df_all_ST_filtered_SNPs_all, 11350)

# Create a list of sets for Euler diagram
sets <- list(
  '20' = intersource_less_20$name_combo,
  '50' = intersource_less_50$name_combo,
  '75' = intersource_less_75$name_combo,
  '100' = intersource_less_100$name_combo,
  '200' = intersource_less_200$name_combo,
  '500' = intersource_less_500$name_combo,
  '1000' = intersource_less_1000$name_combo,
  '2500' = intersource_less_2500$name_combo,
  '5000' = intersource_less_5000$name_combo,
  '7500' = intersource_less_7500$name_combo,
  '11,350' = intersource_total_11350$name_combo
)

# Open a pdf to save our plot to
pdf("../figures/Final_Figures/Figure_3.pdf", width = 12, height = 12)

# Generate and plot the Euler diagram
fit <- euler(sets)
plot(fit,
     quantities = TRUE,
     lty = c(1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2),         # Line types
     fills = rev(c("#FFFFF0",                           # Colors for the fills
                   "grey24",
                   "grey36",
                   "grey48",
                   "grey60",
                   "grey72",
                   "grey84",
                   "#FF6A6A",
                   "#FFA500",
                   "#FFFF00",
                   "#FFFFF0"))
)

# Shut down plotting device
dev.off()
```

# Figure 3 Table for custom annotation

```{r warning=FALSE, message=FALSE}
# Define the breaks and labels for the bins
breaks <- c(0, 20, 50, 75, 100, 200, 500, 1000, 5000, 7500, Inf)
labels <- c("0-20", "21-50", "51-75", "76-100", "101-200", "201-500", "501-1000", "1001-5000", "5001-7500", "7500+")

# Bin the data
binned_SNPs <- df_all_ST_filtered_SNPs_all %>%
  filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
  select(`Sample 1`, `Sample 2`, SNPs) %>%
  mutate(Bin = cut(SNPs, breaks = breaks, labels = labels, right = FALSE))

#Summarize the data by bin
summary <- binned_SNPs %>%
  group_by(Bin) %>%
  summarise(Count = n(), .groups = 'drop')

#Add percentages
summary <- summary %>% mutate(Percentage = scales::percent(Count/sum(summary$Count), accuracy = 0.01))

#Create aggregating column for labels
summary<- summary %>% mutate(label = paste0(Bin, " SNPs (n=",Count,"/", sum(summary$Count), "; ", Percentage, ")"))

# View summary

# Display the final table
knitr::kable(summary, align = 'c')
```

```{r warning=FALSE, message=FALSE}
#The top 10 STs linked to putative clusters (as per cgMLST analyses) comprised _ isolates, _ of which were no closer than 100 SNPs from any other isolates under analysis. From the remaining _ isolates _ clusters emerged, each comprising two or more isolates differing by ≤ 100 SNPs. Of these, _ comprised cross-source clusters, (cluster sizes: min = _, median = _, max = _) and _ comprised mono-source clusters (cluster sizes: min = _, median = _, max = _). 

# Load necessary libraries
library(dplyr)
library(tidyr)

# Create base_table with unique values for each ST.x
base_table <- df_all_ST_filtered_SNPs_all %>%
  group_by(ST.x) %>%                            # Group by ST.x
  select(ST.x, `Sample 1`, `Sample 2`) %>%            # Select the Sample 1 and Sample 2 columns
  distinct() %>%                                # Remove duplicate rows
  pivot_longer(cols = c(`Sample 1`, `Sample 2`), values_to = "unique_value") %>% # Pivot longer to create a single column of unique values
  select(-name) %>%                             # Remove the temporary 'name' column created by pivot_longer
  unique() %>%                                  # Keep only unique rows
  distinct(unique_value) %>%                    # Keep distinct unique values
  tally() %>%                                   # Count the number of unique values
  rename("Count of ST" = n) %>%                 # Rename our column
  bind_rows(summarise(.,                        # Add a row for total
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ "Total")))

# Create count_of_clustered_samples with SNPs less than 100
count_of_clustered_samples <- df_all_ST_filtered_SNPs_all %>%
  filter(SNPs < 100) %>%                        # Filter rows where SNPs are less than 100
  group_by(ST.x) %>%                            # Group by ST.x
  select(ST.x, `Sample 1`, `Sample 2`) %>%            # Select the Sample 1 and Sample 2 columns
  distinct() %>%                                # Remove duplicate rows
  pivot_longer(cols = c(`Sample 1`, `Sample 2`), values_to = "unique_value") %>% # Pivot longer to create a single column of unique values
  select(-name) %>%                             # Remove the temporary 'name' column created by pivot_longer
  unique() %>%                                  # Keep only unique rows
  distinct(unique_value) %>%                    # Keep distinct unique values
  tally() %>%                                   # Count the number of unique values
  rename("Count of Clustered Samples" = n)  %>% # Rename our column
  bind_rows(summarise(.,                        # Add a row for total
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ "Total")))

# Create clusters with Sample 1
clusters_1 <- df_all_ST_filtered_SNPs_all %>%
  select(`Sample 1`, ST.x, Cluster__autocolour.x, Revised_Source_Niche.x) %>% # Select relevant columns
  rename("Sample" = "Sample 1",                # Rename columns for consistency
         "Cluster" = "Cluster__autocolour.x", 
         "Revised_Source_Niche" = "Revised_Source_Niche.x")

# Create clusters with Sample 2 and combine with clusters_1
clusters_2 <- df_all_ST_filtered_SNPs_all %>%
  select(`Sample 2`, ST.x, Cluster__autocolour.y, Revised_Source_Niche.y) %>% # Select relevant columns
  rename("Sample" = "Sample 2",                # Rename columns for consistency
         "Cluster" = "Cluster__autocolour.y", 
         "Revised_Source_Niche" = "Revised_Source_Niche.y")

# Combine the two clusters and remove duplicates
clusters <- bind_rows(clusters_1, clusters_2) %>% unique()

# Count clusters with more than one sample
count_of_clusters <- clusters %>%
  select(-Revised_Source_Niche) %>%             # Exclude Revised_Source_Niche column
  group_by(ST.x, Cluster) %>%                   # Group by ST.x and Cluster
  tally() %>%                                   # Count the number of samples in each cluster
  filter(n > 1) %>%                             # Filter clusters with more than one sample
  group_by(ST.x) %>%                            # Group by ST.x
  tally() %>%                                   # Count the number of clusters
  rename("Count of Clusters" = n) %>%           # Rename our column
  bind_rows(summarise(.,                        # Add a row for total
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ "Total")))

# Identify cross-sectoral clusters
clusters_by_source <- clusters %>%
  mutate(val_col = 1) %>%                       # Add a column with a constant value
  select(-Sample) %>%                           # Remove the Sample column
  pivot_wider(names_from = "Revised_Source_Niche", values_from = "val_col", values_fill = 0, values_fn = sum) %>% # Pivot wider to get sectoral columns
  rowwise() %>%                                 # Operate row-wise
  mutate(Cross_sectoral = sum(c_across(Livestock:`Wild Animal`) > 0) > 1) %>% # Add a column indicating cross-sectoral clusters
  mutate(Cluster_Strain_Count = Livestock + `Companion Animal` + Human + Food + Environmental + `Wild Animal`) # Add a column indicating count of strains per cluster

# Create Cross_and_mono_clusters by filtering clusters with more than one strain, then tallying and pivoting
Cross_and_mono_clusters <- clusters_by_source %>%
  filter(Cluster_Strain_Count > 1) %>%          # Filter clusters with more than one strain
  select(ST.x, Cluster, Cross_sectoral) %>%     # Select relevant columns
  group_by(ST.x, Cross_sectoral == TRUE) %>%    # Group by ST.x and whether the cluster is cross-sectoral
  tally() %>%                                   # Count the number of clusters in each group
  pivot_wider(names_from = `Cross_sectoral == TRUE`, values_from = n, values_fill = 0) %>% # Pivot wider to get separate columns for cross-sectoral and mono-sectoral clusters
  rename("Mono Sectoral Clusters" = `FALSE`,    # Rename columns for clarity
         "Cross Sectoral Clusters" = `TRUE`) %>%# Rename our column
  ungroup %>%
  bind_rows(summarise(.,                        # Add a row for total
                      across(where(is.numeric), sum),
                      across(where(is.character), ~ "Total")))

# Create stats_cross_cluster_size by summarizing cross-sectoral clusters
stats_cross_cluster_size <- clusters_by_source %>%
  filter(Cross_sectoral == TRUE) %>%                                              # Filter cross-sectoral clusters
  group_by(ST.x) %>%                                                              # Group by ST.x
  summarise("Minimum Cross-Source Cluster Size" = min(Cluster_Strain_Count),      # Calculate minimum cluster size
            "Median Cross-Source Cluster Size" = median(Cluster_Strain_Count),    # Calculate median cluster size
            "Maximum Cross-Source Cluster Size" = max(Cluster_Strain_Count)) %>%  # Calculate maximum cluster size
  bind_rows(summarise(.,                                                          # Add a row for total
                      "ST.x" = "Total",
                      "Minimum Cross-Source Cluster Size" = min(`Minimum Cross-Source Cluster Size`),
                      "Median Cross-Source Cluster Size" = median(`Median Cross-Source Cluster Size`),
                      "Maximum Cross-Source Cluster Size" = max(`Maximum Cross-Source Cluster Size`)))

# Combine all the tables into one final table
final_table <- base_table %>%
  left_join(count_of_clustered_samples, by = "ST.x") %>%  # Join with count_of_clustered_samples
  left_join(count_of_clusters, by = "ST.x") %>%           # Join with count_of_clusters
  left_join(Cross_and_mono_clusters, by = "ST.x") %>%     # Join with Cross_and_mono_clusters
  left_join(stats_cross_cluster_size, by = "ST.x") %>%    # Join with stats_cross_cluster_size
  rename("ST" = ST.x) %>%                                 # Rename our column
  mutate(ST = str_replace(ST, "ST", "")) %>%              # Strip out the ST characters
  arrange(desc(`Count of ST`))

# Put row for total at the end
final_row <- final_table %>% filter(ST == "Total") # Extract final row

final_table <- final_table %>% filter(ST != "Total") %>% # Filter out final row
  bind_rows(final_row)                                   # Bind final row back in

# Display the final table
knitr::kable(final_table, align = 'c')

```

# Figure 4

```{r warning=FALSE, message=FALSE}
# Function to read and annotate distances with sequence type
read_and_annotate <- function(file_path, sequence_type) {
  read_delim(file = file_path, delim = "\t", show_col_types = FALSE) %>%
    mutate(ST = sequence_type)
}

# Initialize an empty data frame for distances
distances2 <- tibble()

# List of sequence types and their respective file paths
sequence_types <- c("ST131", "ST117", "ST963", "ST69", "ST457", "ST57", "ST648", "ST1193", "ST80", "ST95")
file_paths <- sprintf("../analysis/SKA/%s_dists/%s_dist_100_SNP.distances.tsv", sequence_types, sequence_types)

# Process each sequence type
for(i in seq_along(sequence_types)) {
  distances <- read_and_annotate(file_paths[i], sequence_types[i])
  distances2 <- bind_rows(distances2, distances)
}

#Filter out unwanted strains
distances2 <- distances2 %>% filter(`Sample 1` %in% genometa$name & `Sample 2` %in% genometa$name)

# Process each unique sequence type in distances2
for(sequence_type in unique(distances2$ST)) {
  set.seed(1)  # For reproducibility

  # Filter and select distances
  dists <- distances2 %>%
    filter(ST == sequence_type, SNPs <= 100) %>%
    select(`Sample 1`, `Sample 2`, SNPs)
  
  # Extract sources from genotypic/metadata table
  sources <- genometa %>%
    filter(paste0("ST", ST_new) == sequence_type) %>%
    select(name, Revised_Source_Niche) %>%
    mutate(color = case_when(
      Revised_Source_Niche == "Companion Animal" ~ "#59398d95",
      Revised_Source_Niche == "Environmental" ~ "#709b4695",
      Revised_Source_Niche == "Food" ~ "#c09f3d95",
      Revised_Source_Niche == "Human" ~ "#48c59595",
      Revised_Source_Niche == "Livestock" ~ "#c26bbc95",
      Revised_Source_Niche == "Wild Animal" ~ "#b9553d95"
    ))

  # Create igraph graph from edge list
  g <- graph_from_data_frame(d = dists, directed = FALSE)
  
  # Assign colors to vertices based on names
  vertex_color_vector <- sources$color[match(V(g)$name, sources$name)]
  
  # Set edge thickness based on SNPs
  E(g)$thickness <- ifelse(E(g)$SNPs <= 20, 3, ifelse(E(g)$SNPs <= 50, 2, 1))

  # Plot graph
  pdf(file = paste0("../figures/Network_graphs/Network_", sequence_type, ".pdf"), width = 11.69, height = 8.27)
  plot(g, edge.width = E(g)$thickness, rescale = TRUE, main = sequence_type, vertex.size = 3, vertex.label = NA, vertex.color = vertex_color_vector)
  legend("bottomleft",
         legend = c("Companion Animal", 
             "Environmental", 
             "Food", 
             "Human", 
             "Livestock", 
             "Wild Animal"),
         fill = c(
           "#59398d95",
           "#709b4695",
           "#c09f3d95",
           "#48c59595",
           "#c26bbc95",
           "#b9553d95"),
         pch=19,
         bty = "n",
         pt.cex = 1,
         cex = 1,
         text.col="black" ,
         horiz = FALSE)
  dev.off()
  
  # Detect communities
  clusters_walktrap <- cluster_walktrap(g)
  
  # Plot communities
  pdf(file = paste0("../figures/Network_graphs/Communities_", sequence_type, ".pdf"), width = 11.69, height = 8.27)
  plot(clusters_walktrap, g, edge.width = E(g)$thickness, rescale = TRUE, main = sequence_type, vertex.size = 3, vertex.label = NA)
  dev.off()
}

```

# Exploring ST95

```{r warning=FALSE, message=FALSE}
#Table of cluster distances
df_all_ST_filtered_SNPs_all %>% filter(ST.x == "ST95") %>% filter(Cluster__autocolour.x == Cluster__autocolour.y) %>% group_by(Cluster__autocolour.x) %>% summarise(minSNPs = min(SNPs), medianSNPs = median(SNPs), maxSNPs = max(SNPs), minAllelicDist = min(value), medianAllelicDist = median(value), maxAllelicDist = max(value), strain_count = n_distinct(c(`Sample 1`, `Sample 2`))) %>% rename("Cluster" = "Cluster__autocolour.x") %>% knitr::kable(., align = 'c')

#Table of cluster distances - only intersource pairs
df_all_ST_filtered_SNPs_all %>% filter(ST.x == "ST95") %>% filter(Cluster__autocolour.x == Cluster__autocolour.y) %>% filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% group_by(Cluster__autocolour.x) %>% summarise(minSNPs = min(SNPs), medianSNPs = median(SNPs), maxSNPs = max(SNPs), minAllelicDist = min(value), medianAllelicDist = median(value), maxAllelicDist = max(value), strain_count = n_distinct(c(`Sample 1`, `Sample 2`))) %>% rename("Cluster" = "Cluster__autocolour.x") %>% knitr::kable(., align = 'c')

#Plot ST95 network
plot(g, edge.width = E(g)$thickness, rescale = TRUE, main = sequence_type, vertex.size = 3, vertex.label = NA, vertex.color = vertex_color_vector)

```

# Exploring phylogenetic distance thresholds using cgMLST and SNP-based approaches

```{r warning=FALSE, message=FALSE}
#Among 1,948 isolates that reside within these STs, _ exhibited both ≤ 100 SNPs and an allelic distance of ≤ 40. 

# Join the cgMLST and SNP-based distances
both_dists <- distances2 %>% left_join(cgmlst_dists) %>%
  #Filter to only include genomes under analysis
  filter(`Sample 1` %in% genometa$name & `Sample 2` %in% genometa$name)

# Produce a table tallying the number of isolates with both ≤ 100 SNPs and an allelic distance of ≤ 40
both_dists %>% group_by(SNPs <= 100 & value <= 40) %>% tally()
```

# Figure 5

```{r warning=FALSE, message=FALSE}

#Define our colour palette
pal <- colorRampPalette(c("red", "yellow", "blue"))
dot_cols <- pal(41)

#Plot our figure
df_all_ST_filtered_SNPs_all %>%
        mutate(source_combo = str_replace(source_combo, 'Companion Animal', 'Comp. Animal')) %>% 
        mutate(source_combo = str_replace(source_combo, 'Environmental', 'Environ.')) %>% 
        filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% 
        filter(value < 40)  %>% 
        mutate(value = as.factor(value)) %>%
        rename('Allelic\nDistance\n(cgMLST)' = value) %>%
        rename('Sequence type' = ST.x) %>%
        ggplot() +
        geom_boxplot(aes(x = SNPs, y = `Sequence type`)) +
        geom_jitter(aes(x = SNPs, y = `Sequence type`, color = `Allelic\nDistance\n(cgMLST)`), size = 0.25) +
        scale_color_manual(values = dot_cols, breaks = as.factor(0:40)) +
        facet_wrap(~source_combo, nrow = 7, ncol = 2, strip.position="right") +
        theme(axis.text.x = element_text(angle = 90)) +
        geom_vline(xintercept = 100, color = "red", linetype = "dashed") +
        scale_x_continuous(breaks = seq(0,1300, by = 100)) +
        guides(colour = guide_legend(override.aes = list(size=1.5), ncol = 1))

#Save our file
ggsave(filename = "../figures/Final_Figures/Figure_5.pdf", width = 8.27, height = 11.69, units = "in", dpi = 300)

#Create a supplementary Table with boxplot counts
df_all_ST_filtered_SNPs_all %>%
    mutate(source_combo = str_replace(source_combo, 'Companion Animal', 'Comp. Animal')) %>% 
    mutate(source_combo = str_replace(source_combo, 'Environmental', 'Environ.')) %>% 
    filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>% 
    filter(value < 40)  %>% 
    mutate(value = as.factor(value)) %>%
    rename('Allelic\nDistance\n(cgMLST)' = value) %>%
    group_by(source_combo, ST.x) %>% tally() %>% rename("Source Combination" = source_combo, "Sequence Type" = ST.x, "Count of Strain Pairs" = n) %>% write_delim("../figures/Final_Figures/Supplementary_Material/Supplementary_Table_4.tsv", delim = "\t")

```

# Supplementary Material

## Supplementary Table 1

```{r warning=FALSE, message=FALSE}

#Generate our supplementary table
genometa %>%
  select(name, ST_new, Revised_Source_Niche, Revised_Source_Type, Intestinal_or_Extraintestinal, Collection, State, Sample_ID, `IncF_RST..IncF RST`) %>%
  rename('Sample name' = name,
         'ST (Pending novel allocation)' = ST_new,
         'Source Niche' = Revised_Source_Niche,
         'Source Type' = Revised_Source_Type,
         "Biosample (Pending allocations)" = 'Sample_ID',
         'IncF RST' = "IncF_RST..IncF RST") %>%
  write_delim("../figures/Final_Figures/Supplementary_Material/Supp_Table_1.tsv", delim = "\t")
```

Supplementary Figure X

## Supplementary Figures

```{r warning=FALSE, message=FALSE}
# Generate a list of STs under analysis
STs <- df_all_ST_filtered_SNPs_all$ST.x %>% unique()

# Generate a list of colours for our STs
ST_cols <- paletteer_d("ggthemes::Tableau_10") %>% as.vector()

# Combine ST cols and names
names(ST_cols) <- STs



plot2 <- df_all_ST_filtered_SNPs_all %>% rename("ST" = "ST.x") %>% filter(SNPs < 12000) %>%
        mutate(fimtyper..Fimtype.x = if_else(is.na(fimtyper..Fimtype.x), "Missing", fimtyper..Fimtype.x)) %>%
        mutate(fimtyper..Fimtype.y = if_else(is.na(fimtyper..Fimtype.y), "Missing", fimtyper..Fimtype.y)) %>%
        mutate(same_fim = if_else(fimtyper..Fimtype.x == fimtyper..Fimtype.y, T, F)) %>% 
        ggplot(aes(x = SNPs, y = value)) + #, color=intra_inter
        geom_point(aes(color = ST), alpha = I(0.2)) +
        labs(x = "Pairwise SNP Distance", y = "Pairwise Allelic Distance") +
        geom_smooth(
                color = "black",
                fill = "#69b3a2",
                se = TRUE
        ) +
        stat_cor(method = "spearman", aes(label = paste(..rr.label.., ..p.label.., sep = "~")), color = "red", geom = "label") +
        scale_color_manual(values = ST_cols)

#ggsave(filename = "../figures/Final_Figures/Supplementary_Material/Supplementary_Figure_3A.pdf", plot = plot2, width = 11.69, height = 8.27, units = "in", dpi = 300)

```

```{r warning=FALSE, message=FALSE}
plot1 <- df_all_ST_filtered_SNPs_all %>% filter(SNPs < 12000) %>%
  mutate(fimtyper..Fimtype.x = if_else(is.na(fimtyper..Fimtype.x), "Missing", fimtyper..Fimtype.x)) %>%
  mutate(fimtyper..Fimtype.y = if_else(is.na(fimtyper..Fimtype.y), "Missing", fimtyper..Fimtype.y)) %>%
  mutate(same_fim = if_else(fimtyper..Fimtype.x == fimtyper..Fimtype.y, T, F)) %>%
  rename("Same FimType" = "same_fim") %>%
        ggplot(aes(x = SNPs, y = value)) + #, color=intra_inter
        geom_point(aes(color = `Same FimType`)) +
        facet_wrap(~ST.x) +
        labs(x = "Pairwise SNP Distance", y = "Pairwise Allelic Distance") +
        geom_smooth(
                color = "red",
                fill = "#69b3a2",
                se = TRUE
        ) +
        stat_cor(method = "spearman", aes(label = paste(..rr.label.., ..p.label.., sep = "~")), color = "red", geom = "label")# +

#ggsave(filename = "../Supplementary_Material/Supplementary_Figure_3B.pdf", plot = plot1, width = 11.69, height = 8.27, units = "in", dpi = 300)
```

```{r, fig.width=12.6, fig.height=8.7}
cgMLST_less_equal_40 <- df_all_ST_filtered_SNPs_all %>% filter(value <= 40) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>%
  pull(unique_value)

SNP_less_equal_100 <- df_all_ST_filtered_SNPs_all %>% filter(SNPs <= 100) %>%
  select(`Sample 1`, `Sample 2`) %>%
  distinct() %>%
  pivot_longer(cols = everything(), values_to = "unique_value") %>%
  distinct(unique_value) %>%
  pull(unique_value)

no_SNP_within <- df_all_ST_filtered_SNPs_all %>% filter(value > 40) %>%
    select(`Sample 1`, `Sample 2`) %>%
    distinct() %>%
    pivot_longer(cols = everything(), values_to = "unique_value") %>%
    distinct(unique_value) %>%
    pull(unique_value)

no_allelic_within <- df_all_ST_filtered_SNPs_all %>% filter(SNPs > 100) %>%
    select(`Sample 1`, `Sample 2`) %>%
    distinct() %>%
    pivot_longer(cols = everything(), values_to = "unique_value") %>%
    distinct(unique_value) %>%
    pull(unique_value)

venn_data <- list("C" = cgMLST_less_equal_40,
                  "S" = SNP_less_equal_100)

# Generate the Venn diagram
plot3 <- ggVennDiagram(venn_data) + 
  theme(legend.position = "none", # Hide legend
        plot.margin = margin(4, 4, 4, 4, "cm")) +
  scale_fill_gradient(low = "white", high = "red") # Customize fill gradient

#ggsave(filename = "../Supplementary_Material/Supplementary_Figure_4A.pdf", plot = plot3, width = 11.69, height = 8.27, units = "in", dpi = 300)
```

```{r, fig.width=12.6, fig.height=8.7}
cgMLST_less_equal_40 <- df_all_ST_filtered_SNPs_all %>% filter(value <= 40) %>%
  mutate(name_combo = paste(`Sample 1`, `Sample 2`)) %>%
  select(name_combo) %>%
  pull(name_combo) %>%
  unique()

SNP_less_equal_100 <- df_all_ST_filtered_SNPs_all %>% filter(SNPs <= 100) %>%
  mutate(name_combo = paste(`Sample 1`, `Sample 2`)) %>%
  select(name_combo) %>%
  pull(name_combo) %>%
  unique()

no_SNP_within <- df_all_ST_filtered_SNPs_all %>% filter(value > 40) %>%
  mutate(name_combo = paste(`Sample 1`, `Sample 2`)) %>%
  select(name_combo) %>%
  pull(name_combo) %>%
  unique()

no_allelic_within <- df_all_ST_filtered_SNPs_all %>% filter(SNPs > 100) %>%
  mutate(name_combo = paste(`Sample 1`, `Sample 2`)) %>%
  select(name_combo) %>%
  pull(name_combo) %>%
  unique()

venn_data <- list("C" = cgMLST_less_equal_40,
                  "S" = SNP_less_equal_100)

# Generate the Venn diagram
plot4 <- ggVennDiagram(venn_data) + 
  theme(legend.position = "none", # Hide legend
        plot.margin = margin(4, 4, 4, 4, "cm")) +
  scale_fill_gradient(low = "white", high = "red") # Customize fill gradient

#ggsave(filename = "../Supplementary_Material/Supplementary_Figure_4B.pdf", plot = plot4, width = 11.69, height = 8.27, units = "in", dpi = 300)
```

```{r warning=FALSE, message=FALSE}
# Calculate the first instance of FALSE for each ST.x group
first_false_positions <- df_all_ST_filtered_SNPs_all %>%
    filter(SNPs <= 300) %>%
    group_by(ST.x) %>%
    filter(Revised_Source_Niche.x != Revised_Source_Niche.y) %>%
    summarize(first_false = min(SNPs, na.rm = TRUE))

# Join the first_false_positions with the main data
plot_data <- df_all_ST_filtered_SNPs_all %>%
    filter(SNPs <= 300) %>%
    group_by(SNPs, Revised_Source_Niche.x == Revised_Source_Niche.y, ST.x) %>%
    tally() %>%
    left_join(first_false_positions, by = "ST.x") %>%
  arrange(desc(n)) %>%
    rename("Same Source" = `Revised_Source_Niche.x == Revised_Source_Niche.y`,
           "SNP Distance" = SNPs,
           "Count of Genome Pairs" = n)

# Create the plot
ggplot(plot_data) +
    geom_bar(aes(x = `SNP Distance`, y = `Count of Genome Pairs`, fill = `Same Source`), stat = "identity") + 
    theme_minimal() +
    facet_wrap(~ ST.x, scales = "free_y", nrow = 5, ncol = 2) +
    geom_vline(aes(xintercept = first_false), linetype = "dashed", color = "red") +
scale_fill_manual(values = c("orange", "black"))
```

```{r warning=FALSE, message=FALSE}
#Save SNP and allelic distance matrix

#Write allelic distances to file
cgmlst_dists %>% write_delim("../Supplementary_Material/allelic_distances.txt", delim = "\t")

#Convert long format SNP dists to wide format
SNP_dists <- df_all_ST_filtered_SNPs_all %>% select(`Sample 1`, `Sample 2`, SNPs)
SNP_dists <- df_all_ST_filtered_SNPs_all %>% select(`Sample 1`, `Sample 2`, SNPs) %>% rename('tmp' = `Sample 1`) %>% rename(`Sample 1` = `Sample 2`) %>% rename(`Sample 2` = tmp) %>% bind_rows(SNP_dists)
SNP_dists <- SNP_dists %>% pivot_wider(names_from = 'Sample 2', values_from = "SNPs", values_fill = 0) %>% column_to_rownames('Sample 1') %>% select(rownames(.))

#Write SNP distances to file
SNP_dists %>% write_delim("../Supplementary_Material/SNP_distances.txt", delim = "\t")

#Generate a long list of SNPs, allelic distance and source
long_distances_w_source <- df_all_ST_filtered_SNPs_all %>% select(`Sample 1`, `Sample 2`, ST.x, ST.y, SNPs, value, Revised_Source_Niche.x, Revised_Source_Niche.y) %>% rename("Allelic Distance" = value, "Source - Sample 1" = Revised_Source_Niche.x,  "Source - Sample 2" = Revised_Source_Niche.y, "Sequence Type - Sample 1" = ST.x, "Sequence Type - Sample 2" = ST.y)

#Write to file
long_distances_w_source %>% write_delim("../figures/Final_Figures/Supplementary_Material/Supp_Table_2.tsv", delim = "\t")
```

# Reviewer requests

```{r warning=FALSE, message=FALSE}
Metadata_Urban_Zoo <- read_delim("../delims/Metadata_Urban_Zoo.txt",
                                 delim = "\t", escape_double = FALSE,
                                 trim_ws = TRUE)

zoo_top_10_STs <- Metadata_Urban_Zoo %>% group_by(`ST(Achtman 7 Gene MLST)`) %>% tally(sort = T) %>% head(10) %>% pull(`ST(Achtman 7 Gene MLST)`)

for(ST in zoo_top_10_STs){
  Metadata_Urban_Zoo %>% filter(`ST(Achtman 7 Gene MLST)` == ST) %>%
    select(`Assembly barcode(Assembly stats)`) %>%
    write_delim(paste0("../Revision/Zoo_ST_lists_top10/","ST", ST, "_names.txt"), delim = "\t")
}

S1_Urban_Zoo <- read_delim("../delims/Extra_metadata_Urban_Zoo_S1.txt",
                                 delim = "\t", escape_double = FALSE,
                                 trim_ws = TRUE)

UZ_meta <- S1_Urban_Zoo %>% mutate("Sample ID" = str_replace(Accession, ".*\\(", "")) %>% mutate("Sample ID" = str_replace(`Sample ID`, "\\)", "")) %>% full_join(Metadata_Urban_Zoo, by = "Sample ID")

UZ_clusters <- read_delim("../Revision/APG_manuscript_1_UZ.clusters.tsv",
                                 delim = "\t", escape_double = FALSE,
                                 trim_ws = TRUE)

UZ_clusters <- UZ_clusters %>% mutate(ID = str_replace(ID, ".result", "")) 

# If "../Revision/APG_manuscript_1_UZ.distances.tsv.gz" is present and "../Revision/APG_manuscript_1_UZ.distances.tsv" isnt, unzip the file
if (file.exists("../Revision/APG_manuscript_1_UZ.distances.tsv.gz") & !file.exists("../Revision/APG_manuscript_1_UZ.distances.tsv")) {
  system("gunzip ../Revision/APG_manuscript_1_UZ.distances.tsv.gz")
}

UZ_dists <- read_delim("../Revision/APG_manuscript_1_UZ.distances.tsv",
                                 delim = "\t", escape_double = FALSE,
                                 trim_ws = TRUE)

UZ_dists <- UZ_dists %>% mutate(`Sample 1` = str_replace(`Sample 1`, ".result", "")) %>% mutate(`Sample 2` = str_replace(`Sample 2`, ".result", ""))

UZ_dists <- UZ_meta %>% rename("Sample 2" = "Assembly barcode(Assembly stats)", "ST" = "ST(Achtman 7 Gene MLST)") %>% select(`Sample 2`, ST, matches("Source_Level"), HHID) %>% full_join(UZ_dists, by ="Sample 2")

UZ_dists <- UZ_meta %>% rename("Sample 1" = "Assembly barcode(Assembly stats)", "ST" = "ST(Achtman 7 Gene MLST)") %>% select(`Sample 1`, ST, matches("Source_Level"), HHID) %>% full_join(UZ_dists, by ="Sample 1")

UZ_dists <- UZ_dists %>% filter(ST.x == ST.y) %>% filter(!is.na(Source_Level3.x)) %>% filter(!is.na(Source_Level3.y))

UZ_dists_less_100 <- UZ_dists %>% filter(SNPs <= 100)

# Create a folder "../Revision/UZ_Network_graphs/" if it doesnt exist
if (!dir.exists("../Revision/UZ_Network_graphs/")) {
  dir.create("../Revision/UZ_Network_graphs/")
}


for(sequence_type in unique(UZ_dists_less_100$ST.x)){

  set.seed(1)
  dists <- UZ_dists_less_100 %>%
    filter(ST.x == ST.y) %>%
    filter(ST.x == sequence_type) %>%
    select(`Sample 1`, `Sample 2`, SNPs)
  
  #Extract sources from genotypic/metadata table
  sources <- UZ_meta %>% filter(`ST(Achtman 7 Gene MLST)` == sequence_type) %>% select("Assembly barcode(Assembly stats)", Source_Level3, HHID) %>% rename("name" = "Assembly barcode(Assembly stats)")

  #Set a colour for each source
  sources <- sources %>%
    mutate(color = case_when(
      Source_Level3 == "human" ~ "#48c59595",
      Source_Level3 == "livestock" ~ "#c26bbc95",
      Source_Level3 == "wildlife" ~ "#b9553d95"
    ))
  
  # Convert data frame to edge list for igraph
  g <- graph_from_data_frame(d = dists, directed = FALSE)
  
  #Get a list of vertex names
  g_vertex_names <- V(g)$name 
  
  # Match colors to vertices based on names
  vertex_color_vector <- sources$color[match(g_vertex_names, sources$name)]
  
    # Match colors to vertices based on names
  HHID_vector <- sources$HHID[match(g_vertex_names, sources$name)]
  
  # Plot the graph
  pdf(file = paste0("../Revision/UZ_Network_graphs/UZ_",
                    sequence_type,
                    ".pdf"),
      width = 11.69,
      height = 8.27)
  
  E(g)$thickness <- ifelse(E(g)$SNPs <= 20, 3,
                           ifelse(E(g)$SNPs <= 50, 2, 1))
  
  
  set.seed(1)
  
  plot(g, edge.width = E(g)$thickness,
       rescale = TRUE,
       main = sequence_type,
       vertex.size = 10,
       vertex.label = HHID_vector,
       vertex.color = vertex_color_vector,
       )
  
  legend("bottomleft",
         legend = c(
             "human", 
             "livestock",
             "wildlife"),
         fill = c(
           "#48c59595",
           "#c26bbc95",
           "#b9553d95"),
         pch=19,
         bty = "n",
         pt.cex = 1,
         cex = 1,
         text.col="black" ,
         horiz = FALSE)
  
  dev.off()

  
}

UZ_dists_less_100 %>% filter(Source_Level3.x != Source_Level3.y) %>% mutate(Region.x = str_replace(HHID.x, "[0-9]+$", ""), Region.y = str_replace(HHID.y, "[0-9]+$", "")) %>% filter(HHID.x != HHID.y) %>% filter(Region.x == Region.y) %>% View()

UZ_dists %>% mutate(Region.x = str_replace(HHID.x, "[0-9]+$", ""), Region.y = str_replace(HHID.y, "[0-9]+$", "")) %>%
  filter(ST.x == ST.y) %>% 
  ggplot(aes(x = SNPs)) +
  geom_histogram(binwidth = 1, 
                 fill = "blue", 
                 color = "black", 
                 alpha = 0.7) +
  labs(title = "Histogram of SNP Distances",
       x = "SNP Distance",
       y = "Frequency") +
  theme_minimal() +
  facet_wrap(~ HHID.x == HHID.y)

```

## PopPunk

```{r warning=FALSE, message=FALSE}

poppunk <- read_csv("../analysis/PopPunk_clusters.csv") %>% rename('name' = Taxon, "PP-Cluster" = Cluster)

SNPs_poppunk <- poppunk %>% rename('Sample 1' = `name`) %>% inner_join(distances2)

SNPs_poppunk <- poppunk %>% rename('Sample 2' = `name`) %>% inner_join(SNPs_poppunk, by = "Sample 2")

SNPs_poppunk <- genometa %>% select(name, ST_new, Revised_Source_Niche) %>% rename("Sample 1" = name) %>% inner_join(SNPs_poppunk)

SNPs_poppunk <- genometa %>% select(name, ST_new, Revised_Source_Niche) %>% rename("Sample 2" = name) %>% inner_join(SNPs_poppunk)

dists_w_punk <- poppunk %>% rename("Sample 1" = name) %>% full_join(cgmlst_dists)

dists_w_punk <- poppunk %>% rename("Sample 2" = name) %>% full_join(dists_w_punk, by = "Sample 2")

#Compute count of PopPunk clusters
poppunk %>% group_by(`PP-Cluster`) %>% tally(sort = T) %>% nrow()

cgmlst_less_40 <- cgmlst_dists %>% filter(value <= 40) 

cgMLST_less_40_g <- graph_from_data_frame(d = cgmlst_less_40, directed = FALSE)

cgMLST_less_40_g %>% cluster_louvain() %>% length()

names_of_ST_members <- genometa %>% filter(paste0("ST", ST_new) %in% STs) %>% pull(name)

cgmlst_less_40_select_ST <- cgmlst_dists %>% filter(value <= 40)  %>% filter(`Sample 1` %in% names_of_ST_members & `Sample 2` %in% names_of_ST_members)

cgmlst_less_40_select_ST_g <- graph_from_data_frame(d = cgmlst_less_40_select_ST, directed = FALSE)

cgmlst_less_40_select_ST_g %>% cluster_louvain() %>% length()

cgmlst_less_40 <- cgmlst_dists %>% filter(value <= 40) 

poppunk %>% filter(name %in% names_of_ST_members)%>% group_by(`PP-Cluster`) %>% tally(sort = T) %>% nrow()

cgmlt_clusts <- graph_from_data_frame(d = cgmlst_dists, directed = FALSE) %>% cluster_louvain()
```

## Subset in time/space

```{r warning=FALSE, message=FALSE}

bird_IDs <- read_delim("../delims/FH_bird_IDs.txt", delim = "\t")

bird_IDs <- bird_IDs %>% filter(Bird != "#N/A")

bird_IDs <- bird_IDs %>% rename('name' = `Genome...2`) %>% select(name, Bird)

poultry_non_dupes <- bird_IDs %>% group_by(Bird) %>% slice_head(n = 1)

poultry_dupes <- bird_IDs %>% filter(name %nin% poultry_non_dupes$name)

genometa %>%
  filter(name %nin% poultry_dupes$name) %>%
    group_by(State, Collection_Year, Revised_Source_Niche) %>%
    tally() %>%
    ggplot(aes(x = Collection_Year, y = n, fill = Revised_Source_Niche)) +
    geom_col(position = "stack") + # Stacked bar chart
    facet_wrap(~ State) + # Facet by State
    labs(
        title = "Number of Samples Collected by State and Year",
        x = "Collection Year",
        y = "Count",
        fill = "Source Niche"
    )  +
scale_fill_manual(
        values = c(source_cols),
        na.value = 'grey'
        ) +
    theme_minimal() # Use a minimal theme for better visualization

vic_subset <- genometa %>% filter(State == "VIC", Collection_Year %in% c(2013, 2014, 2015, 2016, 2017)) %>% pull(name)

vic_dists_cgmlst <- cgmlst_dists %>% filter(`Sample 1` %in% vic_subset & `Sample 2` %in% vic_subset)

vic_dists_cgmlst <- genometa %>% select(name, Revised_Source_Niche, ST_new, Collection_Year) %>% rename(`Sample 1` = name) %>% inner_join(vic_dists_cgmlst, by = "Sample 1")

vic_dists_cgmlst <- genometa %>% select(name, Revised_Source_Niche, ST_new, Collection_Year) %>% rename(`Sample 2` = name) %>% inner_join(vic_dists_cgmlst, by = "Sample 2")

SNPs_subset <- df_all_ST %>% filter(`Sample 1` %in% vic_dists_cgmlst$`Sample 1` & `Sample 2`  %in% vic_dists_cgmlst$`Sample 2`) %>% select(`Sample 1`, `Sample 2`, SNPs)

vic_dists_cgmlst <- left_join(vic_dists_cgmlst, SNPs_subset, by = c("Sample 1", "Sample 2"))

vic_dists_cgmlst <- vic_dists_cgmlst %>% filter(ST_new.x == ST_new.y) %>% filter(!is.na(SNPs))

for(sequence_type in sequence_types){

  set.seed(1)
  dists <- vic_dists_cgmlst %>%
    filter(paste0("ST", ST_new.x) == sequence_type) %>%
    filter(SNPs <= 100) %>%
    select(`Sample 1`, `Sample 2`, SNPs)
  
  #Extract sources from genotypic/metadata table
  sources <- genometa %>% filter(paste0("ST",ST_new) == sequence_type) %>% select(name, Revised_Source_Niche)

  #Set a colour for each source
  sources <- sources %>%
    mutate(color = case_when(
      Revised_Source_Niche == "Captive Animal" ~ "#b5467395",
      Revised_Source_Niche == "Companion Animal" ~ "#59398d95",
      Revised_Source_Niche == "Environmental" ~ "#709b4695",
      Revised_Source_Niche == "Food" ~ "#c09f3d95",
      Revised_Source_Niche == "Human" ~ "#48c59595",
      Revised_Source_Niche == "Livestock" ~ "#c26bbc95",
      Revised_Source_Niche == "Waste" ~ "#6d83da95",
      Revised_Source_Niche == "Wild Animal" ~ "#b9553d95"
    ))
  
  # Convert data frame to edge list for igraph
  g <- graph_from_data_frame(d = dists, directed = FALSE)
  
  #Get a list of vertex names
  g_vertex_names <- V(g)$name 
  
  # Match colors to vertices based on names
  vertex_color_vector <- sources$color[match(g_vertex_names, sources$name)]
  
  # Plot the graph
  pdf(file = paste0("../Revision/Network_graphs/Network_Vic_subset_",
                    sequence_type,
                    ".pdf"),
      width = 11.69,
      height = 8.27)
  
  E(g)$thickness <- ifelse(E(g)$SNPs <= 20, 3,
                           ifelse(E(g)$SNPs <= 50, 2, 1))
  
  
  set.seed(1)
  
  plot(g, edge.width = E(g)$thickness,
       rescale = TRUE,
       main = sequence_type,
       vertex.size = 3,
       vertex.label = NA,
       vertex.color = vertex_color_vector,
       )
  
  legend("bottomleft",
         legend = c("Companion Animal", 
             "Environmental", 
             "Food", 
             "Human", 
             "Livestock",
             "Wild Animal"),
         fill = c(
           "#59398d95",
           "#709b4695",
           "#c09f3d95",
           "#48c59595",
           "#c26bbc95",
           "#b9553d95"),
         pch=19,
         bty = "n",
         pt.cex = 1,
         cex = 1,
         text.col="black" ,
         horiz = FALSE)
  
  dev.off()

  
}



genometa %>%
  filter(name %in% vic_subset) %>% 
  filter(paste0("ST",ST_new) %in% sequence_types) %>%
    group_by(ST_new, Collection_Year, Revised_Source_Niche) %>%
    tally() %>%
    ggplot(aes(x = Collection_Year, y = n, fill = Revised_Source_Niche)) +
    geom_col(position = "stack") + # Stacked bar chart
    facet_wrap(~ ST_new) + # Facet by State
    labs(
        title = "Number of Samples Collected by State and Year",
        x = "Collection Year",
        y = "Count",
        fill = "Source Niche"
    ) +
scale_fill_manual(
        values = c(source_cols),
        na.value = 'grey'
        ) +
    theme_minimal() # Use a minimal theme for better visualization

```

```{r warning=FALSE, message=FALSE}
bird_IDs <- read_delim("../delims/FH_bird_IDs.txt", delim = "\t")

bird_IDs <- bird_IDs %>% filter(Bird != "#N/A")

birdy <- bird_IDs %>% rename("Sample 1" = "Genome...2") %>% inner_join(vic_dists_cgmlst, by = "Sample 1")

birdy <- bird_IDs %>% rename("Sample 2" = "Genome...2") %>% inner_join(birdy, by = "Sample 2")

bird_IDs <- bird_IDs %>% rename('name' = `Genome...2`) %>% select(name, Bird)

for(sequence_type in sequence_types){

  set.seed(1)
  dists <- birdy %>%
    filter(paste0("ST", ST_new.x) == sequence_type) %>%
    filter(SNPs <= 100) %>%
    select(`Sample 1`, `Sample 2`, SNPs)
  
  #Extract sources from genotypic/metadata table
  sources <- genometa %>% full_join(bird_IDs, by = 'name') %>% filter(paste0("ST",ST_new) == sequence_type) %>% select(name, Revised_Source_Niche, Bird)

  #Set a colour for each source
  sources <- sources %>%
    mutate(color = case_when(
      Revised_Source_Niche == "Captive Animal" ~ "#b5467395",
      Revised_Source_Niche == "Companion Animal" ~ "#59398d95",
      Revised_Source_Niche == "Environmental" ~ "#709b4695",
      Revised_Source_Niche == "Food" ~ "#c09f3d95",
      Revised_Source_Niche == "Human" ~ "#48c59595",
      Revised_Source_Niche == "Livestock" ~ "#c26bbc95",
      Revised_Source_Niche == "Waste" ~ "#6d83da95",
      Revised_Source_Niche == "Wild Animal" ~ "#b9553d95"
    ))
  
  # Convert data frame to edge list for igraph
  g <- graph_from_data_frame(d = dists, directed = FALSE)
  
  #Get a list of vertex names
  g_vertex_names <- V(g)$name 
  
  # Match colors to vertices based on names
  vertex_color_vector <- sources$color[match(g_vertex_names, sources$name)]
  
  vertex_bird_ID <- sources$Bird[match(g_vertex_names, sources$name)]
  
  # Plot the graph
  pdf(file = paste0("../Revision/Network_graphs/birdy_Network_Vic_subset_",
                    sequence_type,
                    ".pdf"),
      width = 11.69,
      height = 8.27)
  
  E(g)$thickness <- ifelse(E(g)$SNPs <= 20, 3,
                           ifelse(E(g)$SNPs <= 50, 2, 1))
  
  
  set.seed(1)
  
  plot(g, edge.width = E(g)$thickness,
       rescale = TRUE,
       main = sequence_type,
       vertex.size = 3,
       vertex.label = vertex_bird_ID,
       vertex.color = vertex_color_vector,
       )
  
  legend("bottomleft",
         legend = c("Companion Animal", 
             "Environmental", 
             "Food", 
             "Human", 
             "Livestock",
             "Wild Animal"),
         fill = c(
           "#59398d95",
           "#709b4695",
           "#c09f3d95",
           "#48c59595",
           "#c26bbc95",
           "#b9553d95"),
         pch=19,
         bty = "n",
         pt.cex = 1,
         cex = 1,
         text.col="black" ,
         horiz = FALSE)
  
  dev.off()

  
}
```

```{r warning=FALSE, message=FALSE}

poultry_non_dupes <- bird_IDs %>% group_by(Bird) %>% slice_head(n = 1)

poultry_dupes <- bird_IDs %>% filter(name %nin% poultry_non_dupes$name)

# Process each unique sequence type in distances2
for(sequence_type in unique(distances2$ST)) {
  set.seed(1)  # For reproducibility

  # Filter and select distances
  dists <- distances2 %>%
    filter(`Sample 1` %nin% poultry_dupes$name & `Sample 2` %nin% poultry_dupes$name) %>%
    filter(ST == sequence_type, SNPs <= 100) %>%
    select(`Sample 1`, `Sample 2`, SNPs)
  
  # Extract sources from genotypic/metadata table
  sources <- genometa %>%
    filter(paste0("ST", ST_new) == sequence_type) %>%
    select(name, Revised_Source_Niche) %>%
    mutate(color = case_when(
      Revised_Source_Niche == "Companion Animal" ~ "#59398d95",
      Revised_Source_Niche == "Environmental" ~ "#709b4695",
      Revised_Source_Niche == "Food" ~ "#c09f3d95",
      Revised_Source_Niche == "Human" ~ "#48c59595",
      Revised_Source_Niche == "Livestock" ~ "#c26bbc95",
      Revised_Source_Niche == "Wild Animal" ~ "#b9553d95"
    ))

  # Create igraph graph from edge list
  g <- graph_from_data_frame(d = dists, directed = FALSE)
  
  # Assign colors to vertices based on names
  vertex_color_vector <- sources$color[match(V(g)$name, sources$name)]
  
  # Set edge thickness based on SNPs
  E(g)$thickness <- ifelse(E(g)$SNPs <= 20, 3, ifelse(E(g)$SNPs <= 50, 2, 1))

  # Plot graph
  pdf(file = paste0("../figures/Network_graphs/New_Network_", sequence_type, ".pdf"), width = 11.69, height = 8.27)
  plot(g, edge.width = E(g)$thickness, rescale = TRUE, main = paste0("New ", sequence_type), vertex.size = 3, vertex.label = NA, vertex.color = vertex_color_vector)
  legend("bottomleft",
         legend = c("Companion Animal", 
             "Environmental", 
             "Food", 
             "Human", 
             "Livestock", 
             "Wild Animal"),
         fill = c(
           "#59398d95",
           "#709b4695",
           "#c09f3d95",
           "#48c59595",
           "#c26bbc95",
           "#b9553d95"),
         pch=19,
         bty = "n",
         pt.cex = 1,
         cex = 1,
         text.col="black" ,
         horiz = FALSE)
  dev.off()
  
  # Detect communities
  clusters_walktrap <- cluster_walktrap(g)
  
  # Plot communities
  pdf(file = paste0("../figures/Network_graphs/New_Communities_", sequence_type, ".pdf"), width = 11.69, height = 8.27)
  plot(clusters_walktrap, g, edge.width = E(g)$thickness, rescale = TRUE, main = sequence_type, vertex.size = 3, vertex.label = NA)
  dev.off()
}
```

```{r warning=FALSE, message=FALSE}
genometa %>%
    group_by(State, Collection_Year, Revised_Source_Niche) %>%
    tally() %>%
    ggplot(aes(x = Collection_Year, y = n, fill = Revised_Source_Niche)) +
    geom_col(position = "stack") + # Stacked bar chart
    facet_wrap(~ State) + # Facet by State
    labs(
        title = "Number of Samples Collected by State and Year",
        x = "Collection Year",
        y = "Count",
        fill = "Source Niche"
    )  +
scale_fill_manual(
        values = c(source_cols),
        na.value = 'grey'
        ) +
    theme_minimal() # Use a minimal theme for better visualization

vic_subset <- genometa %>% filter(State == "VIC", Collection_Year %in% c(2013, 2014, 2015, 2016, 2017)) %>% pull(name)

vic_dists_cgmlst <- cgmlst_dists %>% filter(`Sample 1` %in% vic_subset & `Sample 2` %in% vic_subset)

vic_dists_cgmlst <- genometa %>% select(name, Revised_Source_Niche, ST_new, Collection_Year) %>% rename(`Sample 1` = name) %>% inner_join(vic_dists_cgmlst, by = "Sample 1")

vic_dists_cgmlst <- genometa %>% select(name, Revised_Source_Niche, ST_new, Collection_Year) %>% rename(`Sample 2` = name) %>% inner_join(vic_dists_cgmlst, by = "Sample 2")

SNPs_subset <- df_all_ST %>% filter(`Sample 1` %in% vic_dists_cgmlst$`Sample 1` & `Sample 2`  %in% vic_dists_cgmlst$`Sample 2`) %>% select(`Sample 1`, `Sample 2`, SNPs)

vic_dists_cgmlst <- left_join(vic_dists_cgmlst, SNPs_subset, by = c("Sample 1", "Sample 2"))

vic_dists_cgmlst <- vic_dists_cgmlst %>% filter(ST_new.x == ST_new.y) %>% filter(!is.na(SNPs))

vic_dists_cgmlst_no_dupe <- vic_dists_cgmlst %>% filter(`Sample 1` %nin% poultry_dupes$name & `Sample 2` %nin% poultry_dupes$name)

for(sequence_type in sequence_types){

  set.seed(1)
  dists <- vic_dists_cgmlst_no_dupe %>%
    filter(paste0("ST", ST_new.x) == sequence_type) %>%
    filter(SNPs <= 100) %>%
    select(`Sample 1`, `Sample 2`, SNPs)
  
  #Extract sources from genotypic/metadata table
  sources <- genometa %>% filter(paste0("ST",ST_new) == sequence_type) %>% select(name, Revised_Source_Niche, Collection_Year)

  #Set a colour for each source
  sources <- sources %>%
    mutate(color = case_when(
      Revised_Source_Niche == "Captive Animal" ~ "#b5467395",
      Revised_Source_Niche == "Companion Animal" ~ "#59398d95",
      Revised_Source_Niche == "Environmental" ~ "#709b4695",
      Revised_Source_Niche == "Food" ~ "#c09f3d95",
      Revised_Source_Niche == "Human" ~ "#48c59595",
      Revised_Source_Niche == "Livestock" ~ "#c26bbc95",
      Revised_Source_Niche == "Waste" ~ "#6d83da95",
      Revised_Source_Niche == "Wild Animal" ~ "#b9553d95"
    ))
  
  # Convert data frame to edge list for igraph
  g <- graph_from_data_frame(d = dists, directed = FALSE)
  
  #Get a list of vertex names
  g_vertex_names <- V(g)$name 
  
  # Match colors to vertices based on names
  vertex_color_vector <- sources$color[match(g_vertex_names, sources$name)]
  vertex_year_vector <- sources$Collection_Year[match(g_vertex_names, sources$name)]
  
  # Plot the graph
  pdf(file = paste0("../Revision/Network_graphs/Network_Vic_subset_no_dupe_",
                    sequence_type,
                    ".pdf"),
      width = 11.69,
      height = 8.27)
  
  E(g)$thickness <- ifelse(E(g)$SNPs <= 20, 3,
                           ifelse(E(g)$SNPs <= 50, 2, 1))
  
  
  set.seed(1)
  
  plot(g, edge.width = E(g)$thickness,
       rescale = TRUE,
       main = sequence_type,
       vertex.size = 8,
       vertex.label = vertex_year_vector,
       vertex.color = vertex_color_vector,
       )
  
  legend("bottomleft",
         legend = c("Companion Animal", 
             "Environmental", 
             "Food", 
             "Human", 
             "Livestock",
             "Wild Animal"),
         fill = c(
           "#59398d95",
           "#709b4695",
           "#c09f3d95",
           "#48c59595",
           "#c26bbc95",
           "#b9553d95"),
         pch=19,
         bty = "n",
         pt.cex = 1,
         cex = 1,
         text.col="black" ,
         horiz = FALSE)
  
  dev.off()

  
}
```

```{r warning=FALSE, message=FALSE}
genometa %>%
  filter(name %in% vic_subset, name %nin% poultry_dupes$name) %>% 
  filter(paste0("ST",ST_new) %in% sequence_types) %>%
    group_by(ST_new, Collection_Year, Revised_Source_Niche) %>%
    tally() %>%
    ggplot(aes(x = Collection_Year, y = n, fill = Revised_Source_Niche)) +
    geom_col(position = "stack") + # Stacked bar chart
    facet_wrap(~ ST_new) + # Facet by State
    labs(
        title = "Number of Samples Collected by ST and Source",
        x = "Collection Year",
        y = "Count",
        fill = "Source Niche"
    ) +
scale_fill_manual(
        values = c(source_cols),
        na.value = 'grey'
        ) +
    theme_minimal() # Use a minimal theme for better visualization

```

```{r warning=FALSE, message=FALSE}
genometa %>%
    group_by(Collection_Year, Revised_Source_Niche) %>%
    tally() %>%
    ggplot(aes(x = Collection_Year, y = n, fill = Revised_Source_Niche)) +
    geom_col(position = "stack") + # Stacked bar chart
    facet_wrap(~ Revised_Source_Niche) + # Facet by State
    labs(
        title = "Number of Samples Collected by Year and Source",
        x = "Collection Year",
        y = "Count",
        fill = "Source Niche"
    ) +
    scale_fill_manual(
        values = c(source_cols),
        na.value = 'grey'
    ) +
    theme_minimal()
```
